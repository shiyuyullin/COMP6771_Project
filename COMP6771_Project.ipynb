{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "364b04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder,KMNIST\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac5052b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset EMNIST\n",
      "    Number of datapoints: 124800\n",
      "    Root location: .\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(240, 240), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "               Lambda()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "27\n",
      "Dataset EMNIST\n",
      "    Number of datapoints: 20800\n",
      "    Root location: .\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(240, 240), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "               Lambda()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset\n",
    "batch_size = 50\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((240,240)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0)==1 else x),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((240,240)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0)==1 else x),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.EMNIST(\n",
    "    root=\".\",\n",
    "    split=\"letters\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform = train_transform)\n",
    "\n",
    "test_data = torchvision.datasets.EMNIST(\n",
    "    root=\".\",\n",
    "    split=\"letters\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform = test_transform)\n",
    "\n",
    "# Initialize EMINST train and test data loaders. \n",
    "emnist_train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "emnist_test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          drop_last=True)\n",
    "print(train_data)\n",
    "print(len(train_data.classes))\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f14adfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 240, 240])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAApDklEQVR4nO3dSW9bWaLY8f/hPE+SyMtJEjUPlq3qqurX1chLsnhAgCySIECyzgd4i3yDvGwDZJldFkEW2QTILsj48rprssujbM0TKZHiJIoiKVGkON4sKHdXV9dgW5J1KZ4fwFa1XVW6svSvw3vvuecIVVWRJEl7dHd9AJIk/TgZpyRplIxTkjRKxilJGiXjlCSNknFKkkbJOCVJo2ScfUoI8ddCiOdCiIYQ4j/94Pf+pRBiUwhxLoTYEEL8s7s5Suk6hJyE0J+EEP8c6AL/CLCqqvqvrn49DCSAfwr8T+AfA/8VGFdV9fhujlb6EIa7PgDpw6iq+t8AhBCfAZHv/VYEKKuq+j+u/v9/F0JcAJOAjLOPyLe1989zYFMI8U+EEPqrt7QN4M3dHpb0vuTIec+oqtoRQvxn4L8AFqAJ/AtVVS/u9sik9yVHzntGCPFXwL8D/iFgAv4B8B+FEMt3eFjSB5Bx3j/LwJeqqj5XVbWrquoz4Dvgr+72sKT3JePsU0IIgxDCAugBvRDCIoQwAM+Av3w7UgohPgH+EnnO2XfkrZQ+JYT4G+Df/OCX/62qqn8jhPhr4F8DAaAA/AdVVf/9xz1C6bpknJKkUfJtrSRplIxTkjRKxilJGiXjlCSN+tkZQkIIebVIkm6Zqqrix35djpySpFEyTknSKBmnJGmUjFOSNErGKUkaJeOUJI2ScUqSRsk4JUmjZJySpFEyTknSKBmnJGmUjFOSNErGKUkaJeOUJI2ScUqSRsk4JUmjZJySpFEyTknSKBmnJGmUjFOSNErGKUkaJeOUJI2ScUqSRsk4JUmj5Lbz0j0huNqqFDACzatX/5JxSn3KCZjpxWigF6QFhBGMZmjXoFuktz1p9w6P88PJOKU+YwCi4BkHix0QCIMRo9GE2WzBYDRiMlu4rNc4O8mhHh+BWgCOgfadHvn7knFKfcQD9jm8k0uMTkxitdkRgl6QJhMWiwWj0YjFYqFWq5FJp8mkUhTyOVpHCWhmgBOgdsdfx7uRcUp9wAq6cUyhBaYeLTO3sMDExAQ2ey9O4/fi1On1mIwmarUa+XyOg8QBuWyOg0SC7FGKy0wSqikgA9Tv+gv7WT+77bzcZUy6OwIwgC6I0fsA/8IiC4uLPHiwyNz8DLFxJ3Z77+80GsFguPpoBIsezmuQP4aDwwty2WMSiQOOUilSqRTpgwPOD1+hVjeAy7v8IoGf3mVMxilpyNXFHaEHvQ+jbQbX1Dxzi4ssLM4zvzDNwmyA2ZiBkLF3CehHf6qv1IB0E7J5lUSqTiqZJZVMc3h4yNqz52RW/xfq5T53fS76U3HKt7XSHTMAJtBZESY/RpOC0T2MZcTP5Mw0c/NzLCxOMz8TZDpmJWYHs/j5KN+yAVMmiEYEo0Eb2fEJEkchDg4iWK1WvqqUKe6XoFMAtDcOyTilO2IGnRthHsZoVbB6gziDQfxKEEVRUIIKk1NR5mYUpqNOwh5w63tj6/sQgEXAmAGUoCA0bCUWHsds1pHP5XlZTNIofosW74nKOKU74ERnm8QemMGtRPCHQwSDISLRCKGwQkBxEQ45mBixo3g+LMofehvpqAlGQjq6ywqp5Cek9nZJV3ZQ25kb+LpuloxT+rhEEP3QLJHZTxmbmSEUChEKhwmFFUIhF8GQDcUlCNrBLm7+B1TQe1vssliw2x3obTbQma5+R1tvbWWc0kdiBmJYY0tMPfiE5V99yuTUJIGAj4BiJRAwMWzXoZjBrAPTO55Xvi8VqKlwVLoglcpSyeZQ26doLUyQcUofRQA8c4RmHjG/vMzy8jJLj+YYHzcy7NEzYhQ49WAQvRfcTpjQO7NMX8BBqkIymeTyOAXdu7+d8mNknNItsoBuEvvkMrMPl5lfXGTxwSKPlkMsxQwoOtAJEFej5G0F+VYHOG1CItcmkSiQOkzSqGeufkd7ZJzSLTABIfDNEV18yOLDJR4tP2JxcYGFeR0zboHjlkfIH1KBlgrpusrBwRn7e/uUkoeojRwyTmkA6EF40TmX8M0sMjM3x9LDJZYeLrIw72M2KggC3NL55M9RgVILkskmB/EjkoeH1E6PoKvdKXwyTumGWMA0iSO0xOQnn/BgaYmlh/MszoeYmzIRM/We7P/YUUIvzK4KuYbK0dEFh4eHpONxGtUkWry/+ZaMU7oBNoTtEZ6ZZZY//ZTPf/0pj5anWJh2MOUGu+5uovy+Rhdy+RbpozSJeIJyOgGNE7T6lhZknNK1OcD+EO/cr3i4/IjPPv+MTz+f4ZNZK6O23g2UO6dCtq2SzTQ4SqXIHB5QLx+i9UfHZJzSB9IBzt7zlTOPeLC0xPzCAjNzMSZHrQSt2ghTpTc25soq6fQJ6XSaci4N9QLQuuOj+3kyTuk96QE74AbHKMPTD5lbWmJ+cYH5hRlmp1yMeXqze7SirEI22yGdTpM7SlMrHQHnd31Yv0jGKb2jq5ESH1gD6N1+hqJjzC72nrNcXJxnYd7LVAA8+rs/x/wDFXKXKtnsGblMlmIuQ/csj9YftAYZp/RO3MAImAMYhvy4A0GG/CNEx8ZYWFhgZnaWhUUXM0EdfsP1J6nfpAaQK0Aum+foKMXp8RF0tTld74dknNLPsAFBMAbQDY3gUoIElCBKMIgSVBgfH2d6doaZGRPTfvDrtLcQ8gkqR0ct0kdHnGRzdE+zQPmuD+udyDiln+AC5hB+BYeioHwvymAohKIojMcUYjED0z6B7w4mFvwSFTg+g3zumFw2S7GQg2Z/jJog45T+jADhRuhmscwuEolECVw9/KwEFRRFIRgMoAQtjI0Kxk1g02iYlQ5ksh0y6QzZTIZqPklv9b3+IOOUruhAmBCGECb/EoGpeeYW5gkGg/gDAQKBIUZGvPhHbIwMQ8AFAX3vB+guw1SvXl16s4BUoNuFckvl8dYlX369xrdff8Pa88dQ3kLr9za/T8Y58HQgbAjTEBbPHN7xeaYXF5iZmWF6ZpxAwIfP52TIDT43uK3gFmDh7qbitYB6C9pt6HSg1lWptjtU2x0uLjtUqx0ODy747slLXjx+zPabJ3D8ht7C0v1DxjmwLCCc6OxDOLwzeKNTjM3MMj0zzczsOBOTAaaCVtxOgdUCDtG7PHSXF3wugXINUpUWB7kLypUmF9UmtVqLs0qV8/NzqtUq1fMqR0cpEquvOIm/hHoCqN7hkX8YGefAcYFpGKMnjHdoAv/EFGMTk8QmJpicChKLDRELWFG8Ory63sPPd30+qQJnbYiXYG2vxNpaku2tHSrlCtVqlYtqlcvzc5pnFZr1M5rNc6pnWTrlNHTz9MsFoB+ScQ4MF5gUbMoMgegskakppqaniU2MMzbuZizsJOo24XMIbPpfXhP2Y1GBShvepJt89zLLi2dveP70OwrbqzQbZdrtKu3WGbQb0GxAt8XVG1+0PKn9Xcg47z0L6MOYA7MosTmmFhaZX1hgfmGauVkbYx4zPosOi6m3bo+WJhAA1Nqwmm3z1ZMkX/7+W1a++opC/EvUWobeYtBtehH25+j4c2Sc95YO8IF9Au/EQ+YfPmJxaYmHjx6x+MDGg2EjLpPAoNNekG+1gMSFyvOVAl9/9YTn//v/UDr8W9R2nn7d1u99yDjvJS/oxzD4xwjPzrH0aJlHy8ssfzLO8qyZMZPonUtq4X3rj3g7Bpaa8Gb7nGdPX/L62285TX0J7Rz3cZT8MTLOe0MAQyAi6IajDMViRKKjTE1N8eDhAx48iLI4a2TcJNBr4CLP96nf+wsVOFdVCh14/OKSv/t/z/jm978nu/sYmlkGJUyQcfa5q63WxTBCH0U3EmFkPEYwFGQ8FiM6GiUWG2d2dpiZUR2jZu18w98uHaICrS6cdlUKDZV8oUs+16VwXOLZ06c8/v3vSL7+Cqq7aP35y5umle+V9F4EYAbDCHrzOMbAKP7RKJFolEgkSiQSJjoaJBodZjRsZMwLPr02vtkq0FF7F3pyzS7H1Q75fJvj4yb5XIF8Lkcul+Pk+JidNyscbz2Bxg6950sGixa+X9I7E4AdjF6MjkkcwUmU2DiRaJRoNEo4EiISGUFRPET8ehQP+Ay92TxaoAIXKqTOumwfXbK/V+4Fmc+Ty+U4zmQ5zWUpneY4L+XgZB9IM0hvZb9Pxtk33GBwY/LO4FJiBCcmmJicZDwWIxz2E4l6UYYdhLwCjws8QhvLhHxfRYX1fJdXKwVWXm2wu7PDcTZLOZflvJynVs6gVorA2dVLuyvjfQwyTk0S9KYBGAErmNyYh6bxDI8Snp1hPBYjNhFjcjLE2JiHkNeE3yVwmHrLg2jx1kgFWEmrfPddmsffPuHF48cUD7a5rKZRa6fQOac3xe5uN7LVEhnnndIDVnorpJvofTvMYDSDyQYmGxaHF68/QnR6huholJmZGcYngsRG7Uz6zfhsYNX3/mktXYH9vktgKw9Pnx7x5e+/4slXv+d0+0uoZ+g9JSKD/DEyzjthovcw8xA4RsBsRZitGI0mzBYbFqsNs633crndhMJhpmdmCIWCTM8MMx41Ebb1zifvaqHm95FpwOZulbXVDVZXVjjdfAaNPWSUP0/G+VFZAV/v5RjCMBxgKKBgsdqwWC2YTGZsNlvvZbdhs9pwupyEw2FiEzGUoJ7YqJ6QsfeUiNaWBPkxdSB9DIcHWfb39snE96GRQob5y2ScH4UBGAYRBLcf87Cf4UAAv6IwNDyEzWbDYrFiNpuwvo3z6uX1ehkathOJ6FCGBVEBRo1NIvgpKnDcgr2DM3Z39zhIxOlkEkDxrg+tL8g4b50VxCQ4gpj8AYYCgaslP4IEFIWhoSFsNusP4rRisxmw2cDrhSEf+PUC70femeu6Wiqk8yrJZI5UKkU2kQD1kEG9NfK+ZJy3ygimBYzBKbzBIMFgb5Gs4NVCWQElQCAwjM3We6DZZAKbFaxWsFnAqgMHvdVioX+ihF5++RYk0hfs7yXY29lFzcaB07s+tL4h47xNuhC26Dyjs7OEw2GCoSDBUIhAYJhwJIDi1xMYBuvVVutGehMGLPSu4/ZTjN/3dmv3bLFLIpHl8OCQ4+Th1agpvSsZ562xonfOMflgkbn5eYKhEOFwkFBoCEWxEBkRDNt6kwXu0zfhbZiZS9g/uiC+n2R/b5dOdhco3fXh9ZX79HOhLboYvtk5FhYXWXr4ACXoIxx2EB7W43f8ca5rv46OP+ZPwsx0iMePie/HOTmIo3ZSd314fUfGeStGsEeWeLC0xIOlBR4sRQj6jYTd4DPe3cp1t0WlNzXvpAKZ0zaJXJlEvMDL52/YfvGcVn4FVHmu+b5knDfOAyOfMP3Zp3zyq2UePYwwHzMyZAKnvr/PJb+vQ2+y3WkNiqcqh8dV4ocFkofHJJNJDhIHpNZfUzl8Qrclr9B+CBnnjXKB5yGTy3/BZ59/zvInCyxNmgldPUfZD5MGvu/t3paX9J4muWjDRRWqF1Cvw0n5gqNsgaPUMclkmlQyRTqVpJJK0igladUS0CnS7wtt3RUZ542xg/MBseXf8psvvuDzX3/OoyUrUbM2J6L/kgJwUIDzczg773JarlI5P6dcqlAqVTirnHN8XCCXzXJ0dMR5Nku7kKLTPkJtF0Ft0ZsFJEfMDyXjvBFWcCwSffgFv/7tb/n817/m0bKNRXt/hakCTRX2LlQ2dmFjY49K5YziSZFiscjp6SnlUomTkxPOSiXax8eo1Rzdbg7UE1C7/HGDBOm6ZJzXIgAHOBYZXf57fP7Fb/nNF7/hs898fOIFXR+dXKrApQpbpyrPXld49uw1b16tUDw5oVg8oZzPQ6kIl6f0tjUoMWjLhnxsMs4PIgArGMYxeKeILD3gN1/8lr/44jM+/3SIZb/om/mvb7VU2CupfLdS5MvffceTr78msfIMym9jPGEQlwq5SzLO9yIAE+j9GByzuCZmmJie4sHSEp//xSd8+sjH0rDA2mdhdlTI1lVebZV58niFx7//kuTjv4X2CvJizt2Rcb4THWADoxeDNYIjOENoepqp6WmmpiZZeDDF8oKbaV9vPmy/hZm57PLddpXH367z7OtvOHr5Fd32G2SYd0vG+ZN09J6/tIHVg9U1gUMZZyQaZXJqilgsxngswkTMx3TUwpgTbH0Upgo0VMhWu3y7UeZ3f/eGx19+xf7z39GurSHPJ++ejPPPOEC4wOzB6ArgcAVxByNEJ2KEwmEi0ShjYwrj425GR6yEXOA29dY26BdVFU7rkC52eLNzzFdfvebpl19y+OZbmqU3oPbfdnn3kYwTPb0lQzzg8GLyBPB4g3hGFIauHvGKRCJEohFCYTuhkI2wy4TfBjajttfu+aEakK/DQU4lcXRKfC/Hyqs3rDx5zPHmt7Qudq7ClLdCtGBA4zQAXhAj4PRiGwnhG1LwBRRGlN6D0L3nLgMoQQfBkImgy4RiFpiNYNL11x9ch95TlPs52Imfs7l5yN7uHrvb2+y9eUU9/Ypu44BBX4pSa/rpZ+yadIAHhB/sfiz+ICPBCP5gkIDSW5VAUQIEggGCihMlqCfo0eE36LDoQS96L+ifkRJ6uWUuYfsIVteOWFvbZGNtg62NdWo7G3RaW9AtIy/+aM89jvNqzVeMgAv0AfSBIMPRKIFgiGAwSHR0lGAoRCQSIaCYUBQdAZdgRAgsVxd3RJ/dFoE/viltq5C5VFnZb/PmTZLXK695/WqFgxfP6VTWoXvEIGyl16/uSZxGYAiwgbD1PpqsYLMhrDbMbjfBoEJkdJRoNEokEiEcCRMd9RCN6og4wS9A8McS+y1I+GOUXRXOgVxTZS/Z5uXLBC+eP+fFs+ccv3iK2npBbzq7pGX3IE4j6MYRtjGE04nOZsNis/3JKnYutxtFUYhEIoTCIcLhAErQQiQEYTO4+3B0/KEuvSgrXci3VU5OIZtts7eb4fXKChuraxQ311Fbu8gw+0OfxylADGEcmsM7OYnT4cRmt+F0OrHbHdhsVpwuF263m6HhYYKhEcJhD/5h8LthxAg2+jvMLr1nPyptOG6r5AuQz7coHFfJZDLs7uyw/maV9NYa7fNtetPwpH7Q53Ga0TumCS0+YHJqCqfLicPhxOF04HQ4sDscuFx2XG4bw0MOAn49fjd4zL2bJ8a7PvxratGLMt+AXLFLLtfkpHBB7mobvWw6TWJvn/TmKq3COnTTyHPM/tHfceoCOEdnmV9cYGZmBrfbjdPlxOWyYrObcLksuFw6XFbBkB3clt5Sk/0eJfSuwmYbcHgC2dwlmcwZuVz+D/tb5rI58pkMpeQejcI6dI6Qq6z3lz6O04DOPs7YzAyLiwvMzU/h9phxOo24XTqcZnCZwG7ubYVnuUer3LXpjZZbqTb7iTPSRzky6cwfRszjbI5yJk29mEGtHUAni5yO13/6+OfVhyM6xdz8HAsPplmcd+KxgdMAdiOYr2K8L2v2vNUFztqwf9xhY7PA7k6CVCpJNpMln8txmk5zWcjSrR9BO4fcxat/9W+cIkx0cpLpmRgPZh3M+cCi68XYDztvfagWkK7DXvycrc1dtra2SB4ekk8d0czl6NRT0M7T23xWRtnP+jROI8IfZXRslIlYlLFhgbOPngj5UF2g2ISdRJ3N9TivX79ma2ODajJF5yx5NVKeXv2dcn5sv+vTOBW8kSiRaIRI0MXIAISpqnDeUXkZb/L0yS7fPXnCxuPHnKfWoH1Eb6SUU/Dukz6N04+iKCiKn5FhMRBhtlWVF7kOz5+nePb0KWvffMP5wdegytsj91W/LaUKGBDBEOFIlEgkRMB7/0fNDvD6HF48K/Di2TPWnz2lcvidDPOe68M4FbyBEJHRCErAhe+uD+eWdYD9hsqL5xe8evmKlWdPOd59Cp0UMsz7rf/iNAYIRUZ7D0CHe/cw76sOUGjB641LXr18xcvnTznafAb1PeSzl/dfn51zmjH6g4Qi4d52eu67Pp7b0wZO27Ce7vLq1T4vnj/n4NULKK8DF3d9eNJH0GdxjjAUjBKORIhGHfju6dlmBzhpwXYe3qwe8+rlKzZfPKeRfw6U7/jopI+lv+LUu/H6RhgeGcHrE/dijuwP1YCjc9g6rLO2keXli9c8e/yEi+RzIH/Xhyd9RH0UpwCbHavDgd1ux2a76+O5WW/PL3eyXda3i6yt7rC2ts7q8+eUdr6EVhw5sWCw9FGcZrC5cLhc2Gw2rGbuxT2Ut3uUbJZhY6vG2toua6vrrK6ukl9do1FeuZq4LicYDJo+itOKze7GZrf34uzTMNXv/UUVyKsqu/tdXr/OsL62ztrqKnurq1STq9DYBup3d7DSneqjOC2YzXacTidOl5V+fFer0tswqKjCUUUll+9ylKqxvr7Om5UVttbWKOyuwtk6ULzrw5XuWB/FacVmd12dbwqson+GTpXe+j6lLiTKXQ5THRKJAqlkimQyydb6OvtrK7TTm8AhcjcvCfomTh1YHdjcbpwuFzabwHLXh/SO3u5JkmvAbq7N1uYpu7sHxPf2OYjvk9rf4exgHS73gcpdH66kIX0SpwmsTix2OxazGaOpN2pqfexUgboKRxewftBkcyPD+tommxvrHG5ucZrehkoCyCCvxEo/1CdxduCyQrlY4Pi4QC57QT7gRDELtPruVgVqXYifqWwmLllbTbK+ts766hqHG6tcHm1AN0nvspAk/bk+ibMFtTjZ9Rc8c3mx221YrZ/w23kLIZP26nx7e2S3rPJq44z11Tjra2tsbW6S2d6gmX+7Ep68Eiv9tD6JE6BGu7zB/gsHVrsNs9kM6gK/fWAlpLWvQoXkpcqbrTovnm2w+uYNu5ubFPY3aZc2oHOMnLgu/RKt/Vj/glMahVesfWcFIWi1WqjdR3y+aCVo1s52fCfA9oHK2uouL1++ZOPlK84Pt+jWdkAtIh/1kt5Fn8XZBTVH4+gJr79RaTZbNFtNzquPmBh343CA1QoOc2/7dwe9rYw+drDJssrG+hErKyusPn9GdfcVdA7pLSUiL/xI76bP4gRQQU3Tzj5h49s27VaL6nmV+EQMt9uNzWbF43HicOhxusDlBLsNokaB/SPsiZJXYXcfdrZ32V5bo7q9Auomct1Y6X31YZxX1Aydwlds/+6MSrlEfH8cl9uN++rlcrtxu1y9jx4npWkTsyMC3y0uBqYC2TNIJJJsrK+T3FkHdRsZpvQh+jdOAEp0a4/JPC2TjY9i9Xhxutx4fEO4PR58Qz7cbjcOh4NKZQH1kxEWFB2eWwq0BRwdqRweHLK/twvHG8gdvaQP1edxAjSgvY6aK1DLe6mZ3eTdPqwuLy6fF5fHg8fjRafX43JaGHK4cbhuZ7+UMxWKpRr53DHFfB7I3cJnkQbFPYgTemNWpncl9NIGlx7qJR/1gpeS00vR68VmtxHwDxON2Ak4DHhvYfWkszaclsqcFE9Qi0XkHFnpOu5JnHB16//qVYXmCTSdNCsuSqdD7DochMNhxicCTPiHcDpu/ouvVqFcrlA8OYELuQ+mdD39t/reO2nSu22RBTWBerHJyd42iXico1SR3FmXyxu+o9EFzs+hdFqhdFpCPvIlXdc9jfOtLr2R9JRWeZuDeJzDwyOyhRqXN3wBtQGUzzucnpYpn54i45Su657H+ZaK2sxSScQ5SqbIZc85r9/sPJ0acFatUy6XaRVPkOeb0nUNSJwAlzSqB6RSKTKZU0r1zo1ukFdvw2nljNPiKWqliJwJJF3XAMXZpnOZppxJUzguULxs0L6hflSgWlU5LVaoVMqoXfnQtHR9AxQnIATCYMBgNGLU625sIsKlCslsh/h+msNEArV7cEP/ZmmQDVCcAvRmDFYrVqsVi16P7gbqVIF8DbYPssT392keJkCV55vS9Q1QnIAwojcaMRoNGHXXHzlV4KILiWyLra0U+zs7tBv7yEfCpJswQHEKdDoTJlPvZdbprvXFq0C9C4mKyvreMdubW5wmdlHbOeTFIOkmDFCcOnQ6CxaLBYvFiFkvrvXFt1VIX8J6vM76WoK9zU0apR1Qb/IasDTIBihOEMKI0WjEaNRjvMaTKV2g1IG9bJPN9RTra2sU4pt0G3LbBOnmDFCcAt0f4tShv8ZX3lUhdd5lb6fC+voG+6tr1E82QZUr6Uk3Z4Di1KHT27FYrVisRgz6Dxs5VaDZheNih/RRjsODQ0rZA9TmKfJCkHSTBidOoUdvdeNyuXDYTeiv8UhKS4WLapdqtUq1ek6zUUWudiDdtMGJU2fA4HLhcDiwO4wYr/G0dR1oNrvU6nUuLy7oNKvIc03ppg1InAJ0LowuFy6XG4fdjOEaX3ldVanVu9RrNZq1GrRqyDilmzYwcep0vl6YTjtWgxH9h16qVXtva+u1JrVajWb1ApoXcKPT6CVpkOLUu3G5nNjtVuwm3QevgqACtbZKvV6ndlHjsl4F9RI58UC6aQMSpxG9zYPL7cblsmI3gf4a/7bLOjQajd7I2awhR03pNgxGnDoPep8Xt9uN02XFes04Gw2VWq1GvVaj1bxA7nsi3YbBiFMVqKqKqqqAeu1tA/UGMJvNWKwWjEYr92qdNEkzBiTOEt3TUyqVCmeVOpfND58uIACfU8fw8DABRcHjj4JxmOuNxZL05wYjTlp06hXOKhXOzuqcXV7jLFHAsFEQUCwoisJQOIzeGQIsN3i8kjQwcap0OxXOz8+pVmtUG+1rXcJx62B42IASDBKORHB6o6Cz39jRShIMVJxFKqenVM+rVJstWte486EXMOzToygjBEMhXJEIWIPcziYP0qAamDjpntM+O+Ps7IyLaoP2Bw6dAtAJCBgFwZCFSDRKMBzGYlPobd8rSTdjQOIEuu0/xFm9aNC5xmw7HeAyQMBvIhRSiEQi2IaCoLfe2OFK0uDESYd2s0ylXKF63qTZut6cHqOAoB3CETuRaARXKIQwBZBXbaWbMkBxtmk2suQzGTKZMoVa51rnnTpgxAyTUTNT02Emp6aweCdA2G7siKXBNkBxdule5jlN7hPfTxDPVbm8xiVbAZgFjDlgYdLHwsIc/plFdMYot7+5vTQIBihOoFvn/CROPL7PfrxMsd691oNeOsCph1jQwsLiOPMLi5iUBRCumzpiaYANVpy0aJ2nye3tEd9LEi82aV3zMUwdoNhgPjbC4tI8Y4tLCMPMjRytNNgGLE4V2mXKxwkS8TgHyToX7es/7GURMB41MD8fY25+HtvkAyB8EwcsDbABixOgykXpgFQiQSKRI9ls071mnQIIGWF+0sPCwhyzDxbBPn0jRysNrgGME7g4oZDcZ293j929Fo2ueu3R0yBgIqxjYWGamdlZhuYWgYmbOFppQA1mnJxxUjgkdZgkmayQaEFVvd7bWwEEBEzHzCwszjO/uIjOPw84kFdvpQ8xoA8iNqCYJrG1yZuV10Sjf5/zMQvTHoFb/+F/KAIYVwQLixOcFj+nUiqz9W2L1tkWtEtXu4+1kevbSu9iQOME1DzZg3XerETxBwIUCuNczDuJ+fWEzL17mB8y3gWAhzPQaDyg1WphsdtI7E5zWTimWUnTah6jtsrQbtBb67aJjFX6MYMbJxdQ3GH/dQC3x0OpVKJxOUdlwkdt3EzMAVbxYe/7x8wCsWDGZFrG63OTnJ+nWCySz+UonpxQOynSKJ/QbJS4rOfo1k6hXe0dk1woTLoywHECHFM9WuXNcyeVyhn1Wo2zs2nq9RCtaQfjLnDr3z9Qo4CYTWCftxIamiV9EqVUqnFavKB0ek6pVKZUKlEqlTg9KXJ8EOc0u0f9NA6NAlBFjqbSgMfZhlaC8p6JRqVCvV6jVqtxeXlJuz1Be9rBpK8X6PtMZxf0nvlUTOAK65nxO2k0ndRacNZoU2m0qJw3qZSbVCoNdraTbG1ssr+5Tv5gk8vCHrRSgNwhe5ANeJwAdbjcpJ6pctBo0Gg0aFxe0u126XYmUeedTPnAo3v/EVQAdgF2E6im3ljYwUBbNdDpWGm3od1R2ft0hDfrU7xemWP19Wt21t5wsr1Ct7YDlJFvdQeTjBOABnQOaBYapF+1aLfavdX6uip6wwy6OTuzbnBcY09PQW/01QMmQe9P3gAqArfNzLRnhNiEh+ho7+HtFx4fyddu2qUVUI9v6OuU+omM8w/aoGZoVyC/DkIIhE6HwWhAr5/G8tDCvJkP38bhJwh656hDZsEXYyZc9gh2hxm93oDQ6zn4rkPn/Bvg8mY/saR5Ms4/0QE1R/vcTuHQScJux371crlG8U3rCerEtde9/SFx9T8WAQGnjlDITXQ0Si6bIZ1O09k6AHX/Zj+ppHkyzj/TgvYhjbyNI7MZs8WM1WrFbnfgco/gUnpzfm6DEfBYwD9iQVGGCUcihCNR4rtB1HYcee45WGScP6oBjSQXGTMpqwWrzYbb7cYfcOPzmliwiFtbjMQmIOCCUNjH8XGU6FGaZCRK62AEkOeeg0TG+aO6QAku9ikdGNk3GPF4PIz4/bhdMfyzgsAtzUo2AcN2CCoWTiIKmdEo/miEdFKBroxzkMg4f1IHKMLZHif7Rva9PkZGRhga8hEKevF6bmchTAE4BYR8UAy7iUajhEJh0i4FylvITZMGx4A+lfKuOsAxVPZI7+8S349zkDjgMNXm5BY3sjYBfitEQ0aiY2HCkTBWJQiM3N4nlTRHxvmL2kCWemaXg/h+L86DEzKl252/4wDCbhiNOIlEIviVIIjhW/yMktbIt7XvpAnNbY7XfLy227HZbTgcRsyPhpjywW0sJa0HfAYIKjpC4d6eLIdDQTjZAeq38BklrZFxvrML2mffkPj6kvNqlXK5xHH+Uz7/bIKJqB6PGTz0orqp26BmwO+ESCRMMBTCG45SOhkBkjf0GSQtk3G+lzqd+hPyz4r831yeVOqIePwTJqcm8PtHGBm24/eDbwj8OoHn7T8m/uTDOxPAiA6UgJ5IJEIwHKW0H4ZqCnnP8/6Tcb63NrS3qCfSrGTi7G9sMDo5iRIMXr0UAgEFRfETUATDQwK/A3xCYOGPs4G+9+FnGQF/ACLRCKFolLg/ymV1H3nP8/6TcX4QFTiDxhPONzdY3xpj3R3AFlBQQr2LN6FIBCUYJBgMEgoH8PuNBAI6AnbBiF5gEr3dyuDnIxVAwCYIR/xEolH8wSjJ5Ai0C8jR836TcV7bGairUF6jVnYR31aIexQcgQgBJcJIKEQ4GiUciRCJRAhHPITDJoJeHYpJYNP1JtP/XKABIBgURKNRIrEYmcQY7Uya3uNk0n0l47wxKlDpvco7VMvDVHdGOBgJEQ/GCETHCI+NMTY2zujYKKNjQ4yO2oh4BUMmsOl634yfijQaEESiQaKjo8SVcXLHe9A+Q66YcH/JOG+FChRALdA5PuD4ZJdiMsrR3gSpiWnGJifIZScpHMcojLkJh81E3TBs6F2h/TMCFJ0gGLQSiUZRxsY5SY3SLuTp/QdBuo9knLeuBt1DOqUCpfM01eMj8slDjpIpDg8PGRsbIzYRIjvuJTrsQPGAxwo2/jhDpK1C7lylWDzjrFLhslqF1iVy1LzfhKr+9EUFIYS84nCj9IAdjD6M9nHswxHckSjjEzFGR0cZHYswPj7CaMhDZMTEiAv0ethPq7zYKvD4mxVefPeUvedf0Si8APUUeVGo/6mq+qNnMzLOO6EDLKAzI8xBLLYY1kiU4Oho73x0NMp4LMxYVMFoNLC+ccDKyiovnz0jt/qSZvkNqCfIkfN+kHFqlh4wgsGL3jSK0TeK9yrS6OgoJpOJ7e1tNtfWuNxbodvcA86RI+b9IePsCzoQFhAKOtsopmAUYTLR2I/TbeyAmkWOlvePjLMvuenNESoiR8r7S8YpSRr1U3HK5zklSaNknJKkUTJOSdIoGackaZSMU5I0SsYpSRol45QkjZJxSpJGyTglSaNknJKkUTJOSdIoGackaZSMU5I0SsYpSRol45QkjZJxSpJGyTglSaNknJKkUTJOSdIoGackaZSMU5I0SsYpSRol45QkjZJxSpJGyTglSaNknJKkUTJOSdIoGackadTPbmQkSdLdkSOnJGmUjFOSNErGKUkaJeOUJI2ScUqSRsk4JUmj/j/RYtgSHKWg7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize an image and its label\n",
    "image, label = train_data[np.random.randint(len(train_data))]\n",
    "print(image.size())\n",
    "plt.axis('off')\n",
    "# If running this cell gives you error regarding image size please try this:\n",
    "# plt.imshow(image.permute(1,2,0).squeeze(2), cmap='gray')\n",
    "plt.imshow(image.permute(1,2,0))\n",
    "plt.title(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b9b9c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "MobileNetV3(\n",
      "  (features): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (2): ConvNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvNormActivation(\n",
      "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvNormActivation(\n",
      "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): ConvNormActivation(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "    (1): Hardswish()\n",
      "    (2): Dropout(p=0.2, inplace=True)\n",
      "    (3): Linear(in_features=1024, out_features=27, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Checking if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Load MobileNet V3 small\n",
    "mobilenet_v3_small = torchvision.models.mobilenet_v3_small(pretrained=True)\n",
    "mobilenet_v3_small.eval()\n",
    "# Freeze the weights\n",
    "for param in mobilenet_v3_small.parameters():\n",
    "    param.requires_grad = False\n",
    "# Modify the last layer\n",
    "number_features = mobilenet_v3_small.classifier[3].in_features\n",
    "features = list(mobilenet_v3_small.classifier.children())[:-1] # Remove last layer\n",
    "features.extend([torch.nn.Linear(number_features, 27)])\n",
    "mobilenet_v3_small.classifier = torch.nn.Sequential(*features)\n",
    "\n",
    "mobilenet_v3_small.to(device)\n",
    "print(mobilenet_v3_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ea7713c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Conv2d(512, 27, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load SqueezeNet\n",
    "squeezenet = torchvision.models.squeezenet1_0(pretrained=True)\n",
    "squeezenet.eval()\n",
    "# Freeze the weights\n",
    "for param in squeezenet.parameters():\n",
    "    param.requires_grad = False\n",
    "# Modify the classification layers\n",
    "squeezenet.classifier[1] = torch.nn.Conv2d(512, 27, kernel_size=(1,1), stride=(1,1))\n",
    "squeezenet.to(device)\n",
    "print(squeezenet)\n",
    "squeezenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "985dd7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleNetV2(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (stage2): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=58, bias=False)\n",
      "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
      "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
      "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
      "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage3): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage4): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)\n",
      "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
      "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
      "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
      "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(464, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=1024, out_features=27, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load ShuffleNet\n",
    "shufflenet = torchvision.models.shufflenet_v2_x1_0(pretrained=True)\n",
    "shufflenet.eval()\n",
    "# Freeze the weights\n",
    "for param in shufflenet.parameters():\n",
    "    param.requires_grad = False\n",
    "in_features = shufflenet.fc.in_features\n",
    "shufflenet.fc = torch.nn.Linear(in_features, 27, bias=True)\n",
    "print(shufflenet)\n",
    "shufflenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa96d94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet(\n",
      "  (features): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): ConvNormActivation(\n",
      "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (8): ConvNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=True)\n",
      "    (1): Linear(in_features=1280, out_features=27, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load EfficientNet baseline\n",
    "efficientnet_b0 = torchvision.models.efficientnet_b0(pretrained=True)\n",
    "efficientnet_b0.eval()\n",
    "# Freeze the weights\n",
    "for param in efficientnet_b0.parameters():\n",
    "    param.requires_grad = False\n",
    "in_features = efficientnet_b0.classifier[1].in_features\n",
    "efficientnet_b0.classifier[1] = torch.nn.Linear(in_features, 27, bias=True)\n",
    "print(efficientnet_b0) \n",
    "efficientnet_b0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b41abdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=27, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=27, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ResNet18\n",
    "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "resnet18.eval()\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "in_features = resnet18.fc.in_features\n",
    "resnet18.fc = torch.nn.Linear(in_features, 27, bias=True)\n",
    "print(resnet18)\n",
    "resnet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58473850",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "def Train(model,optimizer,dataloader,device):\n",
    "    loss_tracker = []\n",
    "    accuracy_tracker = []\n",
    "    for i,(data,label) in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % batch_size:\n",
    "            print(f'step: {i+1}, loss = {loss.item():.4f}')\n",
    "            with torch.no_grad():\n",
    "                loss_tracker.append(loss.item())\n",
    "                value, predictions = torch.max(outputs,1)\n",
    "#                 print(f'Predictions: {predictions}')\n",
    "#                 print(f'Labels: {label}')\n",
    "                correct_prediction = 0\n",
    "                correct_prediction += (predictions == label).sum().item()\n",
    "                accuracy = correct_prediction / label.shape[0] * 100\n",
    "                accuracy_tracker.append(accuracy)\n",
    "            \n",
    "    return loss_tracker, accuracy_tracker\n",
    "\n",
    "def Test(model,dataloader,device):\n",
    "    loss_tracker = []\n",
    "    accuracy_tracker = []\n",
    "    for i,(data,label) in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward(data)\n",
    "            loss = criterion(outputs, label)\n",
    "            _, predictions = torch.max(outputs,1)\n",
    "            correct_prediction = 0\n",
    "            correct_prediction += (predictions == label).sum().item()\n",
    "            accuracy = correct_prediction / label.shape[0] * 100\n",
    "            \n",
    "        loss_tracker.append(loss.item())\n",
    "        accuracy_tracker.append(accuracy)\n",
    "        \n",
    "    return sum(loss_tracker)/len(loss_tracker), sum(accuracy_tracker)/len(accuracy_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c64d59bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "step: 2, loss = 3.4080\n",
      "step: 3, loss = 3.1815\n",
      "step: 4, loss = 3.2623\n",
      "step: 5, loss = 3.3284\n",
      "step: 6, loss = 3.3376\n",
      "step: 7, loss = 3.2681\n",
      "step: 8, loss = 3.3138\n",
      "step: 9, loss = 3.3769\n",
      "step: 10, loss = 3.3340\n",
      "step: 11, loss = 3.2669\n",
      "step: 12, loss = 3.4097\n",
      "step: 13, loss = 3.3883\n",
      "step: 14, loss = 3.4200\n",
      "step: 15, loss = 3.3487\n",
      "step: 16, loss = 3.2639\n",
      "step: 17, loss = 3.3064\n",
      "step: 18, loss = 3.3128\n",
      "step: 19, loss = 3.3522\n",
      "step: 20, loss = 3.1823\n",
      "step: 21, loss = 3.2817\n",
      "step: 22, loss = 3.3697\n",
      "step: 23, loss = 3.2390\n",
      "step: 24, loss = 3.4151\n",
      "step: 25, loss = 3.3999\n",
      "step: 26, loss = 3.2865\n",
      "step: 27, loss = 3.1922\n",
      "step: 28, loss = 3.2934\n",
      "step: 29, loss = 3.4622\n",
      "step: 30, loss = 3.3027\n",
      "step: 31, loss = 3.2915\n",
      "step: 32, loss = 3.2458\n",
      "step: 33, loss = 3.3968\n",
      "step: 34, loss = 3.3076\n",
      "step: 35, loss = 3.1907\n",
      "step: 36, loss = 3.4097\n",
      "step: 37, loss = 3.2832\n",
      "step: 38, loss = 3.3942\n",
      "step: 39, loss = 3.4192\n",
      "step: 40, loss = 3.3124\n",
      "step: 41, loss = 3.3960\n",
      "step: 42, loss = 3.4811\n",
      "step: 43, loss = 3.3809\n",
      "step: 44, loss = 3.3425\n",
      "step: 45, loss = 3.3122\n",
      "step: 46, loss = 3.3832\n",
      "step: 47, loss = 3.2335\n",
      "step: 48, loss = 3.3429\n",
      "step: 49, loss = 3.3167\n",
      "step: 50, loss = 3.3885\n",
      "step: 52, loss = 3.2167\n",
      "step: 53, loss = 3.4560\n",
      "step: 54, loss = 3.1766\n",
      "step: 55, loss = 3.3531\n",
      "step: 56, loss = 3.3605\n",
      "step: 57, loss = 3.2275\n",
      "step: 58, loss = 3.3313\n",
      "step: 59, loss = 3.3968\n",
      "step: 60, loss = 3.4245\n",
      "step: 61, loss = 3.4834\n",
      "step: 62, loss = 3.3946\n",
      "step: 63, loss = 3.5186\n",
      "step: 64, loss = 3.3892\n",
      "step: 65, loss = 3.4006\n",
      "step: 66, loss = 3.3986\n",
      "step: 67, loss = 3.3927\n",
      "step: 68, loss = 3.2773\n",
      "step: 69, loss = 3.3857\n",
      "step: 70, loss = 3.3471\n",
      "step: 71, loss = 3.4165\n",
      "step: 72, loss = 3.4557\n",
      "step: 73, loss = 3.4227\n",
      "step: 74, loss = 3.3801\n",
      "step: 75, loss = 3.3489\n",
      "step: 76, loss = 3.3474\n",
      "step: 77, loss = 3.2976\n",
      "step: 78, loss = 3.3901\n",
      "step: 79, loss = 3.4256\n",
      "step: 80, loss = 3.3283\n",
      "step: 81, loss = 3.4429\n",
      "step: 82, loss = 3.4318\n",
      "step: 83, loss = 3.1968\n",
      "step: 84, loss = 3.4331\n",
      "step: 85, loss = 3.3333\n",
      "step: 86, loss = 3.4242\n",
      "step: 87, loss = 3.3738\n",
      "step: 88, loss = 3.3229\n",
      "step: 89, loss = 3.3839\n",
      "step: 90, loss = 3.4486\n",
      "step: 91, loss = 3.4269\n",
      "step: 92, loss = 3.3777\n",
      "step: 93, loss = 3.3915\n",
      "step: 94, loss = 3.3745\n",
      "step: 95, loss = 3.4064\n",
      "step: 96, loss = 3.3853\n",
      "step: 97, loss = 3.4041\n",
      "step: 98, loss = 3.3662\n",
      "step: 99, loss = 3.3631\n",
      "step: 100, loss = 3.3372\n",
      "step: 102, loss = 3.3086\n",
      "step: 103, loss = 3.3855\n",
      "step: 104, loss = 3.3243\n",
      "step: 105, loss = 3.3619\n",
      "step: 106, loss = 3.4063\n",
      "step: 107, loss = 3.3711\n",
      "step: 108, loss = 3.3789\n",
      "step: 109, loss = 3.3461\n",
      "step: 110, loss = 3.3643\n",
      "step: 111, loss = 3.3852\n",
      "step: 112, loss = 3.4396\n",
      "step: 113, loss = 3.1993\n",
      "step: 114, loss = 3.3222\n",
      "step: 115, loss = 3.2961\n",
      "step: 116, loss = 3.3206\n",
      "step: 117, loss = 3.2657\n",
      "step: 118, loss = 3.3056\n",
      "step: 119, loss = 3.3035\n",
      "step: 120, loss = 3.2794\n",
      "step: 121, loss = 3.3324\n",
      "step: 122, loss = 3.4778\n",
      "step: 123, loss = 3.3056\n",
      "step: 124, loss = 3.4602\n",
      "step: 125, loss = 3.3320\n",
      "step: 126, loss = 3.3021\n",
      "step: 127, loss = 3.2909\n",
      "step: 128, loss = 3.2779\n",
      "step: 129, loss = 3.3548\n",
      "step: 130, loss = 3.3722\n",
      "step: 131, loss = 3.3119\n",
      "step: 132, loss = 3.3777\n",
      "step: 133, loss = 3.3622\n",
      "step: 134, loss = 3.2386\n",
      "step: 135, loss = 3.3800\n",
      "step: 136, loss = 3.3477\n",
      "step: 137, loss = 3.4976\n",
      "step: 138, loss = 3.2414\n",
      "step: 139, loss = 3.3078\n",
      "step: 140, loss = 3.3552\n",
      "step: 141, loss = 3.2751\n",
      "step: 142, loss = 3.3692\n",
      "step: 143, loss = 3.3716\n",
      "step: 144, loss = 3.3256\n",
      "step: 145, loss = 3.3560\n",
      "step: 146, loss = 3.2560\n",
      "step: 147, loss = 3.4052\n",
      "step: 148, loss = 3.4018\n",
      "step: 149, loss = 3.3553\n",
      "step: 150, loss = 3.3809\n",
      "step: 152, loss = 3.2913\n",
      "step: 153, loss = 3.3541\n",
      "step: 154, loss = 3.4458\n",
      "step: 155, loss = 3.3678\n",
      "step: 156, loss = 3.3249\n",
      "step: 157, loss = 3.3831\n",
      "step: 158, loss = 3.2961\n",
      "step: 159, loss = 3.3298\n",
      "step: 160, loss = 3.2686\n",
      "step: 161, loss = 3.2550\n",
      "step: 162, loss = 3.3533\n",
      "step: 163, loss = 3.3020\n",
      "step: 164, loss = 3.3555\n",
      "step: 165, loss = 3.4346\n",
      "step: 166, loss = 3.3138\n",
      "step: 167, loss = 3.2392\n",
      "step: 168, loss = 3.3799\n",
      "step: 169, loss = 3.3969\n",
      "step: 170, loss = 3.3686\n",
      "step: 171, loss = 3.2693\n",
      "step: 172, loss = 3.5642\n",
      "step: 173, loss = 3.4227\n",
      "step: 174, loss = 3.3317\n",
      "step: 175, loss = 3.3635\n",
      "step: 176, loss = 3.3210\n",
      "step: 177, loss = 3.3511\n",
      "step: 178, loss = 3.3813\n",
      "step: 179, loss = 3.2989\n",
      "step: 180, loss = 3.3837\n",
      "step: 181, loss = 3.2236\n",
      "step: 182, loss = 3.3497\n",
      "step: 183, loss = 3.3326\n",
      "step: 184, loss = 3.2992\n",
      "step: 185, loss = 3.3528\n",
      "step: 186, loss = 3.4521\n",
      "step: 187, loss = 3.3245\n",
      "step: 188, loss = 3.2747\n",
      "step: 189, loss = 3.3724\n",
      "step: 190, loss = 3.3324\n",
      "step: 191, loss = 3.3881\n",
      "step: 192, loss = 3.3160\n",
      "step: 193, loss = 3.3597\n",
      "step: 194, loss = 3.3212\n",
      "step: 195, loss = 3.2526\n",
      "step: 196, loss = 3.2881\n",
      "step: 197, loss = 3.3838\n",
      "step: 198, loss = 3.3337\n",
      "step: 199, loss = 3.4705\n",
      "step: 200, loss = 3.3451\n",
      "step: 202, loss = 3.3095\n",
      "step: 203, loss = 3.3367\n",
      "step: 204, loss = 3.4688\n",
      "step: 205, loss = 3.3291\n",
      "step: 206, loss = 3.4028\n",
      "step: 207, loss = 3.3256\n",
      "step: 208, loss = 3.3619\n",
      "step: 209, loss = 3.3380\n",
      "step: 210, loss = 3.3963\n",
      "step: 211, loss = 3.3691\n",
      "step: 212, loss = 3.2031\n",
      "step: 213, loss = 3.2950\n",
      "step: 214, loss = 3.3875\n",
      "step: 215, loss = 3.3819\n",
      "step: 216, loss = 3.3792\n",
      "step: 217, loss = 3.4331\n",
      "step: 218, loss = 3.3175\n",
      "step: 219, loss = 3.3803\n",
      "step: 220, loss = 3.2621\n",
      "step: 221, loss = 3.5071\n",
      "step: 222, loss = 3.3033\n",
      "step: 223, loss = 3.4484\n",
      "step: 224, loss = 3.3542\n",
      "step: 225, loss = 3.3624\n",
      "step: 226, loss = 3.3371\n",
      "step: 227, loss = 3.3561\n",
      "step: 228, loss = 3.3524\n",
      "step: 229, loss = 3.3148\n",
      "step: 230, loss = 3.2214\n",
      "step: 231, loss = 3.2560\n",
      "step: 232, loss = 3.3371\n",
      "step: 233, loss = 3.3570\n",
      "step: 234, loss = 3.3324\n",
      "step: 235, loss = 3.3430\n",
      "step: 236, loss = 3.4485\n",
      "step: 237, loss = 3.4528\n",
      "step: 238, loss = 3.3448\n",
      "step: 239, loss = 3.3980\n",
      "step: 240, loss = 3.3696\n",
      "step: 241, loss = 3.3551\n",
      "step: 242, loss = 3.3611\n",
      "step: 243, loss = 3.3556\n",
      "step: 244, loss = 3.4232\n",
      "step: 245, loss = 3.3317\n",
      "step: 246, loss = 3.3570\n",
      "step: 247, loss = 3.4309\n",
      "step: 248, loss = 3.3219\n",
      "step: 249, loss = 3.3201\n",
      "step: 250, loss = 3.3815\n",
      "step: 252, loss = 3.4561\n",
      "step: 253, loss = 3.4349\n",
      "step: 254, loss = 3.3061\n",
      "step: 255, loss = 3.4140\n",
      "step: 256, loss = 3.2968\n",
      "step: 257, loss = 3.3893\n",
      "step: 258, loss = 3.3214\n",
      "step: 259, loss = 3.2828\n",
      "step: 260, loss = 3.3542\n",
      "step: 261, loss = 3.2980\n",
      "step: 262, loss = 3.3658\n",
      "step: 263, loss = 3.4437\n",
      "step: 264, loss = 3.3500\n",
      "step: 265, loss = 3.2845\n",
      "step: 266, loss = 3.3346\n",
      "step: 267, loss = 3.4437\n",
      "step: 268, loss = 3.3013\n",
      "step: 269, loss = 3.2824\n",
      "step: 270, loss = 3.4004\n",
      "step: 271, loss = 3.3062\n",
      "step: 272, loss = 3.4236\n",
      "step: 273, loss = 3.3475\n",
      "step: 274, loss = 3.3304\n",
      "step: 275, loss = 3.2988\n",
      "step: 276, loss = 3.3552\n",
      "step: 277, loss = 3.4837\n",
      "step: 278, loss = 3.2080\n",
      "step: 279, loss = 3.3278\n",
      "step: 280, loss = 3.3440\n",
      "step: 281, loss = 3.3323\n",
      "step: 282, loss = 3.3187\n",
      "step: 283, loss = 3.3368\n",
      "step: 284, loss = 3.3153\n",
      "step: 285, loss = 3.3083\n",
      "step: 286, loss = 3.3882\n",
      "step: 287, loss = 3.2688\n",
      "step: 288, loss = 3.2997\n",
      "step: 289, loss = 3.2569\n",
      "step: 290, loss = 3.3726\n",
      "step: 291, loss = 3.3885\n",
      "step: 292, loss = 3.2590\n",
      "step: 293, loss = 3.3476\n",
      "step: 294, loss = 3.3705\n",
      "step: 295, loss = 3.2540\n",
      "step: 296, loss = 3.3672\n",
      "step: 297, loss = 3.2903\n",
      "step: 298, loss = 3.4206\n",
      "step: 299, loss = 3.4072\n",
      "step: 300, loss = 3.2103\n",
      "step: 302, loss = 3.4094\n",
      "step: 303, loss = 3.3707\n",
      "step: 304, loss = 3.3181\n",
      "step: 305, loss = 3.2713\n",
      "step: 306, loss = 3.4539\n",
      "step: 307, loss = 3.4052\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17340/3955749858.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch: {epoch}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0memnist_train_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0memnist_test_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mtrain_loss_tracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17340/1876298799.py\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(model, optimizer, dataloader, device)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mloss_tracker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0maccuracy_tracker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \"\"\"\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'std evaluated to zero after conversion to {}, leading to division by zero.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(mobilenet_v3_small.parameters(), lr = learning_rate)\n",
    "model = resnet18\n",
    "\n",
    "train_loss_tracker = []\n",
    "train_accuracy_tracker = []\n",
    "\n",
    "test_loss_tracker = []\n",
    "test_accuracy_tracker = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    train_loss,train_accuracy = Train(model,optimizer,emnist_train_loader,device)\n",
    "    test_loss , test_accuracy = Test(model,emnist_test_loader,device)\n",
    "    train_loss_tracker.extend(train_loss)\n",
    "    train_accuracy_tracker.extend(train_accuracy)\n",
    "    test_loss_tracker.append(test_loss)\n",
    "    test_accuracy_tracker.append(test_accuracy)\n",
    "    print('\\t training loss/accuracy: {0:.2f}/{1:.2f}'.format(sum(train_loss)/len(train_loss), sum(train_accuracy)/len((train_accuracy))))\n",
    "    print('\\t testing loss/accuracy: {0:.2f}/{1:.2f}'.format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a4731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
